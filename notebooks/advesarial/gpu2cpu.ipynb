{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['THEANO_FLAGS'] = 'floatX=float32,device=cpu'#very important theano is initialized with cpu\n",
    "\n",
    "import subprocess\n",
    "import cPickle\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from copy import copy\n",
    "\n",
    "import blocks\n",
    "from blocks.bricks import Linear, Softmax, Softplus, NDimensionalSoftmax, BatchNormalizedMLP,\\\n",
    "                          Rectifier, Logistic, Tanh, MLP\n",
    "from blocks.bricks.recurrent import GatedRecurrent, Fork, LSTM\n",
    "from blocks.initialization import Constant, IsotropicGaussian, Identity, Uniform\n",
    "from blocks.bricks.cost import BinaryCrossEntropy, CategoricalCrossEntropy\n",
    "from blocks.filter import VariableFilter\n",
    "from blocks.roles import PARAMETER\n",
    "from blocks.graph import ComputationGraph\n",
    "\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "\n",
    "module_logger = logging.getLogger(__name__)\n",
    "sys.setrecursionlimit(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pickleFile(thing2save, file2save2=None, filePath='/work/notebooks/drawModels/', fileName='myModels'):  # pragma: no cover\n",
    "    if file2save2 is None:\n",
    "        f = file(filePath+fileName+'.pickle', 'wb')\n",
    "    else:\n",
    "        f = file(filePath+file2save2, 'wb')\n",
    "\n",
    "    cPickle.dump(thing2save, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "\n",
    "def loadFile(filePath):  # pragma: no cover\n",
    "    file2open = file(filePath, 'rb')\n",
    "    loadedFile = cPickle.load(file2open)\n",
    "    file2open.close()\n",
    "    return loadedFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertgpu2cpu(gpuLoadModelPath, cpuSaveModelPath, cpuModelName = 'cpuVersion'):\n",
    "    gpumodel = loadFile(gpuLoadModelPath)\n",
    "    \n",
    "    ################################################\n",
    "    # This model graph has to be the EXACT graph used to generate the gpumodel\n",
    "    ################################################\n",
    "    \n",
    "    ######Model graph\n",
    "    \n",
    "    X = T.tensor4('inputs')\n",
    "    Y = T.matrix('targets')\n",
    "    rnnType = 'gru'\n",
    "\n",
    "    #data specifics\n",
    "    dimIn = 257\n",
    "    maxPackets = 8\n",
    "    dim = 100\n",
    "    numClasses = 4\n",
    "\n",
    "    ###ENCODER\n",
    "    if rnnType == 'gru':\n",
    "        rnn = GatedRecurrent(dim=dim)\n",
    "        dimMultiplier = 2\n",
    "    else:\n",
    "        rnn = LSTM(dim=dim)\n",
    "        dimMultiplier = 4\n",
    "\n",
    "    fork = Fork(output_names=['linear', 'gates'], input_dim=dimIn, output_dims=[dim, dim * dimMultiplier])\n",
    "\n",
    "    ###CONTEXT\n",
    "    if rnnType == 'gru':\n",
    "        rnnContext = GatedRecurrent(dim=dim)\n",
    "    else:\n",
    "        rnnContext = LSTM(dim=dim)\n",
    "\n",
    "    forkContext = Fork(output_names=['linearContext', 'gatesContext'], input_dim=dim, output_dims=[dim, dim * dimMultiplier])\n",
    "\n",
    "    forkDec = Fork(output_names=['linearOut', 'gatesOut'], input_dim=dim, output_dims=[dim, dim*dimMultiplier])\n",
    "\n",
    "    #CLASSIFIER\n",
    "    bmlp = BatchNormalizedMLP( activations=[Logistic(),Logistic()],dims=[dim, dim, numClasses])\n",
    "\n",
    "    ####No initialization needed\n",
    "    \n",
    "    def onestepEnc(X):\n",
    "        data1, data2 = fork.apply(X) \n",
    "\n",
    "        if rnnType == 'gru':\n",
    "            hEnc = rnn.apply(data1, data2) \n",
    "        else:\n",
    "            hEnc, _ = rnn.apply(data2)\n",
    "\n",
    "        return hEnc\n",
    "\n",
    "    hEnc, _ = theano.scan(onestepEnc, X) #(mini*numPackets, packetLen, 1, hexdictLen)\n",
    "    hEncReshape = T.reshape(hEnc[:,-1], (-1, maxPackets, 1, dim)) #[:,-1] takes the last rep for each packet\n",
    "                                                                 #(mini, numPackets, 1, dimReduced)\n",
    "\n",
    "    def onestepContext(hEncReshape):\n",
    "\n",
    "        data3, data4 = forkContext.apply(hEncReshape)\n",
    "\n",
    "        if rnnType == 'gru':\n",
    "            hContext = rnnContext.apply(data3, data4)\n",
    "        else:\n",
    "            hContext, _ = rnnContext.apply(data4)\n",
    "\n",
    "        return hContext\n",
    "\n",
    "\n",
    "    hContext, _ = theano.scan(onestepContext, hEncReshape)\n",
    "    hContextReshape = T.reshape(hContext[:,-1], (-1,dim))\n",
    "\n",
    "    data5, _ = forkDec.apply(hContextReshape)\n",
    "\n",
    "    pyx = bmlp.apply(data5)\n",
    "    softmax = Softmax()\n",
    "    softoutClass = softmax.apply(pyx)\n",
    "\n",
    "    cpumodel = theano.function([X], softoutClass, allow_input_downcast=True)\n",
    "    \n",
    "    #Now both gpumodel and cpumodel have the same parameters, load cpumode's parameters with gpumodel's\n",
    "    for wt in range(len(cpumodel.get_shared())):\n",
    "        cpumodel.get_shared()[wt].set_value(gpumodel.get_shared()[wt].get_value())\n",
    "    \n",
    "    pickleFile(cpumodel, filePath=cpuSaveModelPath, fileName=cpuModelName)\n",
    "    \n",
    "    return cpumodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test\n",
    "cpumodel = convertgpu2cpu(gpuLoadModelPath = '/data/fs4/home/bradh/outputs/hredClassify8fullpacketsPREDICT61500.pickle', \n",
    "                          cpuSaveModelPath = '/data/fs4/home/bradh/outputs/', \n",
    "                          cpuModelName = 'cpuVersion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
